{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stardust75R/test-google-colab/blob/main/signateFoundryVGG16_ipynb_%E3%81%AEsigmoid2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0lR6j9MzV4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a90d82-0dad-4b28-fb02-17c5eb6a3d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWjXEDvPzvpx"
      },
      "outputs": [],
      "source": [
        "dir_name = \"/content/gdrive/My Drive/ColabData/signate2/foundry/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWcnvDt8z0Oo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_curve, roc_auc_score,classification_report\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDSSdMZv5Dn9"
      },
      "outputs": [],
      "source": [
        "seed = 11235\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BdsBYfGLz8LH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b437366-a386-4a53-b613-78c0842c1fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['label_master.tsv', 'train_master.tsv', 'test_images', 'train_images(1)']\n"
          ]
        }
      ],
      "source": [
        "img_size1 = 96\n",
        "img_size2 = 96     #画像のサイズ(今回は96*96)\n",
        "channels = 128            #画像のチャンネル数を調整\n",
        "max_epoch = 200         #学習のエポック数を調整、より多くの学習ができる\n",
        "mini_batch_size = 256   #ミニバッチサイズを調整\n",
        "dropout_rate = 0.8    #ドロップアウト率を調整。モデル表現力を低下させ、過学習を防ぐために用いられる\n",
        "learning_rate = 0.001 #学習スピードを調整\n",
        "lambda1 = 0.0001        #L1正則化の係数を調整。L1正則化は過学習防止に用いられる\n",
        "lambda2 = 0.0001\n",
        "\n",
        "print(os.listdir(dir_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jIdKxM80CwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be77114-1960-4ff3-e586-3b0f6649623d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     file_name  label_id\n",
            "0  train_0.jpg         1\n",
            "1  train_1.jpg         5\n",
            "2  train_2.jpg         1\n",
            "3  train_3.jpg         6\n",
            "4  train_4.jpg         3\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(os.path.join(dir_name,'train_master.tsv'), delimiter='\\t')\n",
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AkJPLpU03Sm"
      },
      "outputs": [],
      "source": [
        "dir_name_train = 'train_images(1)/'\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=45,width_shift_range=0.2,height_shift_range=0.2,zoom_range=0.2,horizontal_flip=False,fill_mode='bicubic')\n",
        "\n",
        "imgarray = []\n",
        "category = []\n",
        "\n",
        "for filename in sorted(os.listdir(os.path.join(dir_name, dir_name_train))):\n",
        "  img = keras.preprocessing.image.load_img(os.path.join(dir_name, dir_name_train, filename), color_mode=\"rgb\", target_size=(img_size1, img_size2,3))\n",
        "  imgdata = keras.preprocessing.image.img_to_array(img)\n",
        "  imgdata = imgdata / 255.0\n",
        "  imgarray.append(imgdata)\n",
        "  temp = df[df['file_name']==filename].file_name\n",
        "  label = df[df['file_name']==filename].label_id.values[0]\n",
        "  category.append(label)\n",
        "\n",
        "imgarray = np.array(imgarray)\n",
        "category = np.array(category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vez2Gi3K3AFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0215bd78-0b4a-426a-ab0d-e87df3437b9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape =  (3500, 96, 96, 3) t_train.shape =  (3500,)\n",
            "x_valid.shape =  (1500, 96, 96, 3) t_valid.shape =  (1500,)\n"
          ]
        }
      ],
      "source": [
        "x_train, x_valid, t_train, t_valid = train_test_split(imgarray, category, test_size=0.3, random_state=0)\n",
        "\n",
        "print(\"x_train.shape = \", x_train.shape, \"t_train.shape = \", t_train.shape)\n",
        "print(\"x_valid.shape = \", x_valid.shape, \"t_valid.shape = \", t_valid.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjCsdStR3F-O"
      },
      "outputs": [],
      "source": [
        "train_labels = keras.utils.to_categorical(t_train, num_classes=10)\n",
        "valid_labels = keras.utils.to_categorical(t_valid, num_classes=10) #ワンホットエンコードする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilo8NfNs3U8u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24ba0f8-91ac-4899-a6c7-4439fca8341b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 96, 96, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 96, 96, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 48, 48, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 48, 48, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 24, 24, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 24, 24, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 0 (0.00 Byte)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 3, 3, 512)         14714688  \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 3, 3, 512)         2048      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 3, 3, 128)         589952    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 2, 2, 128)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15440586 (58.90 MB)\n",
            "Trainable params: 724874 (2.77 MB)\n",
            "Non-trainable params: 14715712 (56.14 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "\n",
        "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(img_size1, img_size2,3))\n",
        "conv_base.trainable = False\n",
        "conv_base.summary()\n",
        "\n",
        "\n",
        "network = keras.models.Sequential()\n",
        "\n",
        "network.add(conv_base)\n",
        "\n",
        "network.add(keras.layers.BatchNormalization())\n",
        "network.add(keras.layers.Conv2D(filters=channels, kernel_size=(3,3), strides=(1,1), padding='same', activation='elu'))\n",
        "network.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=None, padding='same'))\n",
        "\n",
        "network.add(keras.layers.Flatten())\n",
        "\n",
        "network.add(keras.layers.Dropout(dropout_rate))\n",
        "network.add(keras.layers.Dense(units=256, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=lambda1,l2=lambda2)))\n",
        "network.add(keras.layers.Dense(units=10,  activation='softmax')) #変更したところ\n",
        "\n",
        "opt = keras.optimizers.RMSprop(lr=learning_rate)\n",
        "network.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "network.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOnRPE3f5c_i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a86ffb-ea09-4416-e0de-96a0994aaad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "14/14 [==============================] - 619s 45s/step - loss: 2.7642 - accuracy: 0.4060 - val_loss: 2.1872 - val_accuracy: 0.4380\n",
            "Epoch 2/200\n",
            " 3/14 [=====>........................] - ETA: 5:33 - loss: 1.8528 - accuracy: 0.5807"
          ]
        }
      ],
      "source": [
        "history = network.fit(x_train, train_labels, epochs=max_epoch, batch_size=mini_batch_size, validation_data=(x_valid, valid_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovvSIk0h7gt5"
      },
      "outputs": [],
      "source": [
        "network.save('model.h5', include_optimizer=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5abtavF_8afF"
      },
      "outputs": [],
      "source": [
        "acc_train  = np.array(history.history['accuracy'])\n",
        "acc_valid  = history.history['val_accuracy']\n",
        "loss_train = history.history['loss']\n",
        "loss_valid = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA0sxWd68ckb"
      },
      "outputs": [],
      "source": [
        "epochs = range(1, len(loss_train) + 1)\n",
        "plt.plot(epochs, loss_train, 'bo', label='Training loss')\n",
        "plt.plot(epochs, loss_valid, 'b',  label='Validatoin loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vtebhzww8hK1"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, acc_train, 'bo', label='Training acc')\n",
        "plt.plot(epochs, acc_valid, 'b',  label='Validation acc')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.0, 1.1])\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdFEf41M8lez"
      },
      "outputs": [],
      "source": [
        "y_train_predict = network.predict(x_train)\n",
        "t_train_predict = np.argmax(y_train_predict, axis=1)\n",
        "print(confusion_matrix(t_train, t_train_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGI7-OsH9HAj"
      },
      "outputs": [],
      "source": [
        "y_valid_predict = network.predict(x_valid)\n",
        "t_valid_predict = np.argmax(y_valid_predict, axis=1)\n",
        "print(confusion_matrix(t_valid, t_valid_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLiNhhqe9MV9"
      },
      "outputs": [],
      "source": [
        "dir_name_test = os.path.join('test_images/')\n",
        "\n",
        "imgarray = []\n",
        "filenamearray = []\n",
        "\n",
        "for filename in sorted(os.listdir(os.path.join(dir_name, dir_name_test))):\n",
        "  img = keras.preprocessing.image.load_img(os.path.join(dir_name, dir_name_test, filename), color_mode=\"rgb\", target_size=(img_size1, img_size2))\n",
        "  imgdata = keras.preprocessing.image.img_to_array(img)\n",
        "  imgdata = imgdata / 255.0\n",
        "  imgarray.append(imgdata)\n",
        "  filenamearray.append(filename)\n",
        "\n",
        "x_test = np.array(imgarray)\n",
        "print(\"x_test.shape = \", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATozFj5Q-gYQ"
      },
      "outputs": [],
      "source": [
        "y_test = network.predict(x_test)\n",
        "t_test_predict = np.argmax(y_test,axis=1)\n",
        "\n",
        "# ファイルのオープン\n",
        "f = open('submit.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "# 1 行ずつ書き込み\n",
        "for n in range(0, len(t_test_predict)):\n",
        "  # image_id を文字列に変換\n",
        "  image_id = str(filenamearray[n])\n",
        "\n",
        "  # label を 0 から 9 の整数に変換\n",
        "  label = int(t_test_predict[n])\n",
        "\n",
        "  # 1 行に 2 つの列を書き込む\n",
        "  f.write('{}\\t{}\\n'.format(image_id, label))\n",
        "\n",
        "# ファイルのクローズ\n",
        "f.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}